# 58期-人工智能该怎么帮我们

## 本期链接

[第58期 人工智能该怎么帮我们 – 后互联网时代的乱弹 (wetime.com)](https://pie.wetime.com/podcast/ep58/)

## 正文

主持人李骏老师 00:00
 好，各位朋友大家好，欢迎来到后互联网时代的论坛，今天我们照例在周末跟我们的老朋友老庄。

庄老师 00:08
 大家好。

主持人李骏老师 00:09
 还有王老师。

王老师 00:10
 大家好。

主持人李骏老师 00:12
 我们一起来聊聊天。我们又攒了一批跟AI有关的事，最近有一些比较重要的新发展，所以我们今天又要重点聊一聊跟人工智能有关的话题了，说实话。不是我们蹭热度，这是这东西实在是避不开，而且是这个时代可能接下来十几二十年都会影响最深远的事情。


 也别看我们几个都是老家伙在这个行业里这么多年了，但是碰到这种级别的正在进行时的大变革，也就这一次，因为上一波互联网，那个时候我们刚毕业还什么都不懂，只能看着跟着走而已，现在不一样可以有一些判断和分析了。所以我们今天会重点聊一聊。


 另外还有一些近期的一些小新闻话题，今天在此之前我先要跟大家说一个事儿，我们这个节目一直是有两个版本，一个是视频的版本是放在b站，还有一个是纯音频的版本，就是照顾我们比较习惯于用一些 pocus一些播客工具的朋友。


 那么纯音频的版本，我们以前是自己有一个服务器在host，最近为了提升质量，也包括长远的服务更加可靠和稳定，我们就做了一个迁移到一个新的服务商。


 这样做的后果，我们音频的播客，他的订阅用的RSS就发生了改变，那么对我们不同的听友影响是不一样的，比如说如果你习惯在b站听的话，其实没有任何影响，因为它本来就是独立的一套，它是视频的格式，然后如果你听音频的话，有两个平台我们是自动的就迁移好了，它后台就无缝迁移了，你什么都不用动，一个是苹果的 podcast的，如果你是用苹果的podcast的, 以前搜索，并且关注我们这个节目的话，你什么都不用做，另一个就是小宇宙也是后台无缝迁移了。


 那么如果你通过小宇宙来订阅的，你也什么都不用做。除了这两个平台以外，如果你是使用其podcast的工具，手工订阅我们的rss的，那么你必须要手工去改一下 rss改成什么呢？我们这一期和下一期的节目的说明，文字里面都会给出链接，你看到你就赶紧把它改掉。我们老的平台 RSS会工作到这个月底，从5月份开始它就停了，不会继续提供服务了。所以大家在剩下的半个月的时间里面，一定要记得把 rss改掉。这个是节目之前我们要特别跟大家强调的一个事儿。


 Ok那就开始我们今天的话题，今天第一个话题我们来聊一聊我们行内的一位老朋友叫吴军，这也算是这个行业的大佬了，他最近有一次访谈，关于目前正如火如荼的AI生成相关的一些内容发表了一些高见，这些高见显然非常多的人不满意也不赞同，于是就引发了江湖大战。


 这个事请我们老庄来跟我们说一说。

庄老师 03:27
 这位大佬其实是一位我会愿意称他为一位著名的科普作家，其他的头衔都不重要。其实是这样很厉害的, 很厉害，19 19 67年出生，毕业于清华大学和约翰霍普金斯大学计算机专业博士，前谷歌高级资深研究员，原腾讯副总裁以及硅谷的风险投资人，而且他是自然语言模型专家，他原来读大学的时候跟了一位就是NLP的大佬，最开始就是研究language model，然后在他跟记者的描述里面，他还说了说语言模型这4个汉字就是我发明的，当然也被人嘲讽了，说language model被翻译成语言模型，这件事情需要你发明吗？


 对，但是他会这样说，然后他在接受采访的时候还讲故事上来就讲了一个非常精彩的故事，大概的意思就是哥伦布当年到了牙买加，然后是怎么样去忽悠人家当地土人呢？


 就跟人家说当地土人说马上就要有月食了，这个月食就是被我被我的上帝对吧，把你们的月亮给干掉了，如果你们向我们祈求要赎回自己的罪过，然后我再把月亮还给你们，大概是这个意思，然后他就把土人吓个半死，然后人家土人就敬他为神明，然后我还特别特别有意思，我就去查了一下当年哥伦布为什么干这事儿。


 其实人家哥伦布到牙买加的时候，当地土人对他们挺好的，但这帮船员就是哥伦布带的这帮船员，本身就是一帮半匪半船员的这帮人，偷人家当地土人东西，不诚信，其实就是还没人家土人诚信，然后人家土人在6个月后实在忍无可忍，说不再提供食物给他们，然后他就想了这一招了，随身带了本万年历，算好了月食，然后去吓唬人家土人。


 但是吴军拿这个例子就是说你只要掌握了规律，这些事情就毫不稀奇，其实有道理。他这个话是有道理的，故事稍微有点狗血，因为它并不是一个很光彩的故事，但是它说明了一个道理，就是你只要理解开普勒行星运动三定理，然后学会推算日食月食，你就可以去吓唬土人。

主持人李骏老师 05:56
 这不就是利用信息差割韭菜。

庄老师 06:00
 对，然后他的意思就是说 ChatGPT这个东西，就1972年他的导师著名的自然语言的大佬叫什么？杰里尼克, 带领的团队就研发了 Language model，然后他还说当年我就做过语言模型，他那个时候做的是一个非常巨大的语言模型，多少个参数？


 有600万个参数，然后说现在ChatGPT，这不就是参数多了点吗？后来我还专门查了一下，我找了一下bing的 chat去问了一下目前最大的大语言模型的参数，目前是16,000亿个参数。


 其实这个是一个很有意思的事情就是说当你做过600万参数的模型，然后你觉得现在的2,000亿或者是16,000亿个参数模型没啥的时候，其实他完全忽略了什么叫做数量级，这还不是一个数量级，这是多少个数量级，从百万到千万到亿，然后再到16,000亿的数量级的差异，然后他觉得这没啥，这是第一个，他认为这个没啥了不起的一个基本的原因，就是以前当年都多少，年前我干过。


 第二个的话他举了两个就是他认为他的ChatGPT能干的事情，然后一个就是回答问题，为什么天空是蓝色的，或者是怎么样去做一个什么烤蛋糕诸如此类的，他说 ChatGPT回答的很好，但没啥，这个技术本身没有太多神秘的地方，然后又说到计算机写作，说大家觉得ChatGPT写东西写得挺好，但是我当年2014年我离开离开谷歌的时候，我花了两天的时间还让计算机写了一首诗，写的还挺好，所以大家看一下这个怎么办呢？


 这就证明这东西也没啥，其实槽点太多知道吧？因为他所谓的没啥事，他分开来做这些事情，无论是写诗也好，还是回答问题也好，它背后用的是比如说写诗用的是什么模型，然后回答问题用的是什么模型都不一样的。


 但现在一个ChatGPT的大模型，它其实是涌现出了各种各样的能力在一个模型里，这才是它背后令人吃惊的地方。但这件事情吴军不提，或者是他没有意识到这件，这就是我觉得这是他一个重大的问题，因为他资格太老了，他见过东西太多了，那么在a在b在c好像原来都有曾经的计算机技术都能做，那么现在有一个新的工具出来，有一个新的技术出来，ABC在同一个模型下做到这件事情，他没有意识到。


 还有一个槽点其实是什么，有人在问他对于中国会怎么样，然后他其实说了一段话，我觉得很震惊，他的意思是说中国搞不成，因为太费钱了，光硬件知道我们缺钱吗？


 对，他的意思是说他说中国的大部分研究机构做不了不是研究水平的问题，而是因为ChatGPT太耗资源，光硬件成本差不多10亿美元耗电还耗得非常大，然后怎么样. 中国有多少家大公司已经有了足够强大的云计算资源，这件事情我觉得吴军还是在腾讯待过的，他在做腾讯搜索的时候，虽然是十几年前，但是他应该对腾讯的计算规模有所了解，更不要说与腾讯等量齐观的更多巨头。


 他又忘了这是第二个事情。


 第三个事情就是所谓的 ChatGPT到底对我们有什么影响？他的意思就是说内容创造的人不会受影响，这是他的一个断言，他就说我们人类是更有创意的，更有智慧的，所以我们能够创造的内容 AI创造不出来更是瞎扯，因为怎么说。

主持人李骏老师 10:25
 影响很大。

庄老师 10:29
 太像乔姆斯基了，这些大佬好像都是拿着自己的东西去去想象 ChatGPT, 他没有真正的好好的用过，或者说这些大佬太忙，没空真的去使用一些新技术，然后亲身的体会一下，感受一下，探索一下。


 他只是拿着他自己过去的当年的经验来怎么说来说这个没啥，当然整个这个东西我要批评的也就到此为止了，他最后说的一些话我是同意的，比如说你不要恐惧对吧？你不要勉强去找什么机会，而且你要识破那些所谓的阴谋家或者想割韭菜的人的那些把戏，你不要被割了韭菜，这个很对，为什么很对？


 我要说另外一篇文章，有篇文章的标题就非常的醒目，叫56岁的吴军固步自封，67岁的比尔盖茨空杯上路, 多好听，然后他也是类似于就是说把吴军批了一通，讲了一堆，然后1234他问题，问题在哪儿？他的观点有什么问题，然后他就还截了一堆的图，就别人对他是怎么嘲讽的，说了很多，最后有一段话就开始讲到，比吴军更大牌的叫李开复，人家不这么想对吧？


 说 AI是一次重大的 open AI带来的一次重大的技术革命，然后比李开复更大牌的叫比尔盖茨，也不这么想，人家怎么样？


 所以你看你吴军怎么回事，你吴军认为普通人没机会，只是那些卖资源的卖 GPU的才有机会，所以怎么样？绝大多数人就真的没机会了吗？好，他就又开始这篇文章就开始举例子，就说短视频刚刚起来的时候，也没有人知道怎么通过短视频挣钱，平台上都是一堆草根在瞎玩，但是你想不想到现在短视频平台已经有多少人在上面赚钱了？


 行文至此，顺便推一把我的知识星球。

主持人李骏老师 12:47
 图穷匕见。

庄老师 12:51
 对了，这个知识星球的名字我就不提了，这个凡是加入本星球的，要送一个ChatGPT账号，再送一个new bing的账号，再手把手教大家使用，小白都能看懂，这个而且不满意可以退款，目前星球优惠价239每满100人再涨10块。

主持人李骏老师 13:16
 现身说法，这就是两种活法。

庄老师 13:18
 对，就是说吴军当然我们可以批评他，但是吴军所批评的割韭菜的人是实实在在存在的。

主持人李骏老师 13:26
 所以这个就非常的有意思。

庄老师 13:30
 咱们就作为一个现象跟大家稍微综述一下。

主持人李骏老师 13:37
 王老师怎么看？

王老师 13:40
 吴军在科普领域里面我觉得还是非常成功的，包括在数学对吧，还有计算机原理那一块，但是我总感觉就是像这一类人很多时候都会犯像经验主义对吧？特别是他就是研究领域的人。对刚才庄老师介绍有详细了解了一下，吴军他就是从事语言模型这一块的一些事情。


 对，他很多时候往往会带着这种经验，然后去看现在的一些新东西，我也感觉他应该并没有去深度的去做过尝试，而且这种科普类大佬，他应该也对他自己的文笔，包括内容创作应该足够自信，所以说我估计他应该是看到了那些可能是不屑于跟我说你们生成的实际的啥，肯定还是得我来，我估计他有这种预设，然后他就会去看这种新的东西了。

主持人李骏老师 14:45
 其实我以前总结过人类前进的路径是什么呢？就是人类里面最聪明最强大的一批人，他们把自己的经验还有一些知识把它固化成工具，这个工具就极大的降低门槛，然后提升工作效率，然后把它给不如自己的那些人来用，这样整个人类的平均水平就提升了。然后他就可以继续前进，去挖掘、去发明创造更新的东西，更强的东西，所以人类实际上就这么个过程，就是把人类的精华浓缩在工具和可复制的一些体系里面。


 所以其实像open ai做的这几个东西，在顶级的内容创作者看起来确实不够看，他写的文章肯定不如我写得好，他写的我也看不上，但是它可以让很多很trivial的工作变得毫无意义。


 也就是说, 如果其实这个话说起来有点伤人，如果有很多看到叉PPT写那些文章，觉得塞写的比我还好，其实这个意味着什么？意味着你其实就是平均线以下的，但是你想想平均线以下的有一半人。


 你这伤了两遍你知道吗？你伤人伤了两遍，

16:09
 如果我们不用平均线我们用这个能力的中位数的话。可能一半都不止三遍。

主持人李骏老师 16:18
 但是人类就是这样子的，没有办法的，大家得得接受这个现实，所有的人都提升肯定是好事，所以那些在某些领域能力高于中位数高于平均线的人，他得有一个责任感，我能不能够把我的经验和能力把它变成一种可复制的东西。


 现在很明显在往这个路上狂奔，不论是写的文章也好，程序代码也好，顶尖高手来看，你都会觉得肯定不怎么样，就这么回事，但是他确实能帮到很多人，包括他的那些问答性的东西，有经验的人，他会觉得说我去网上搜，我也能很快得到类似信息和数据，而且说不定我查证的可靠性比恰具体好，所以我可能更相信我自己的做的这些工作，这个是很正常的，但是你要知道ChatGPT现在的准确度可能已经有7080%，在大部分情况下对很多人来讲他就够用了，所以我觉得这个是一个上限和平均数的问题，是完全不同的，你指望现在的生成AI提升人类的上限，我觉得这是不现实的，但是它会显著的提升我们的平均数，这个就不得了了，这个就会带来产业和整个社会的革命性的变化，是不是一定会不知道，但是有可能性，所以从这个角度上来讲的话，其实说实话我不是特别理解吴军同志他的发言，他是可能是不是在访谈当中聊嗨了，这哥们的背景是非常好的，这也许这个名气上李开复比他大，但其实从背景上来讲，这两个人是一个level就。


 开复其实是很早就转了管理方面的工作了，所以他技术上他更像是一个有技术背景的管理。


 职业经理人和投资者。


 吴军当然现在也号称做风险投资了，赚了钱之后投点钱这个没什么很正常，但吴军本质上一直还是做技术的时间比较长，他真正转型是什么时候？


 也就10来年时间，我觉得有点像上次上礼拜荐书的时候，我提到的那几个围棋的棋手，做技术做着发现我好像写书更爽，不论是写的过程还是赚钱的效率，好像我这个写书做报告会更快，所以就转到那边去了，但有过很强的技术背景的人，他多少得有一点怎么说呢？


 你说叫偶像包袱或者叫面子，他在技术问题上不能乱讲，他如果像他这种讲法的话，真的会砸他的牌子，我觉得。


 他这次讲话就像刚才老庄说，除了最后的那三个结论以外，其他基本上没什么靠谱的说法。


 三个结论导师没错，说得很好，但是他论证这三个结论的过程和解释他的一些话语就是让人看了看不下去，尤其是做技术背景的，我跟老庄一个共同的朋友在微博上直接毫不客气的。

说话人5 19:49
 就是说。

主持人李骏老师 19:51
 吴老师你变成了自己年轻时候痛恨的那种人。

说话人5 20:01
 就这个事儿。

主持人李骏老师 20:03
 有了一定阅历之后，人容易傲慢，确实是这样子的，尤其是那种一辈子都很成功的，没怎么吃过苦头的人。


 但是我觉得真正比较有点智慧的，还是就一直要努力提醒自己要跟着这个时代前进。


 他说的几个观点里面，我觉得一个是刚才老庄说过的规模化的效应，实际上做到1万多亿个参数之后，大模型也并不一定起质变。比如说麦塔跟Google早就有规模超过GPT3.5的规模的模型存在，但是他们没有做出像ChatGPT这样的应用，而openAI做出来了，这个里面不完全是模型规模的问题，里边还是真的有创新的。


 我不知道我觉得吴军他周围的人对这个应该是有认知的，他自己也不可能完全不知道，我甚至有点怀疑，他说这些很多话是制造话题还是怎么着，搞不清楚。过于无知，你无法判断它到底是真的还是假的。

庄老师 21:07
 可以略过了。他的这些东西，完了以后他再说就可以不用管这种感觉。

主持人李骏老师 21:14
 对这次其实我跟大家讲，这哥们在行业内的口碑一直差不多是这样，大家都心知肚明，但是这一次有很多有一定面子的人就站出来直接去喷，当然不是刚才老庄说卖知识星球那种，有一些是技术领域里面真的还是有点脸面的，人也出来写了一些文章说他的问题，那就说明这个真的是有点过界了，你装可以你不能装到这种程度是吧？


 所以反过来也是提醒我们节目的听友有一些人他的阅历很光鲜，而且也过去有一些非常优秀的作品，他有他的感染力在里面，也因此打动了很多人，把很多人引到这条路上来。他讲数学讲计算机科学的一些原理型的一些书，我觉得还是不错的，这些都是不可否认的，但是现在突然开始胡说八道了，就这种胡说八道程度，超过ChatGPT胡说八道的程度。

王老师 22:20
 大家也要ChatGPT复审。

主持人李骏老师 22:23
 我现在在微博上骂人就喜欢用这个模板，就是你这说的还ChatGP有逻辑的,是非常有效。


 这个话题我们先说到这。第二个我们来聊一聊Elon Mask, 我们有一阵子没提他了，这哥们在最近有一系列的骚操作。


 //一个是它成立了一家新的壳公司，这个公司叫x, 这很有meta的风格或者Google的风格，Google是成立了一个大的壳公司叫alphabet，然后把它所有的业务都装进去了，包括主流业务和未来的创新的业务。


 然后facebook也是有一个大的壳叫meta，然后下面装了一个东西. 他现在成立了新能够叫x, 然后把他的什么tesla Space x还有其他的一些公司都装进去了。


 然后他据说在组织一个叫x.AI的公司， x.ai实际上就是他的野心里面要跟Open AI来竞争的公司。


 大家知道最早open ai 成立的时候，Elon Mask,是它的联合创始人之一，然后后来他就退出了，退出的原因他自己的表述是这样的，他说open AI违背了初衷不够open，这是他自己的表述，但是圈内的传闻是他在open AI内部争权失败了，争一把手的这个位置没有成功。


 所以他就控制不了，他就干脆退出了。


 不管怎么样，总之她跟open ai 有渊源，换句话说也就是旧仇新恨一起来了，所以他现在准备煮新的爱，在联想到他积极参与的，让open ai 停止6个月训练的这样的倡议。


 不管他主观意愿是什么，大家都会这么去想对吧？


 然后在推特上面，他最近做了几个事情都挺轰动的，我们今天要重点聊的是他最近的提的观点一个想法。我们知道Twitter现在在卖他的会员服务，而且艾德马斯克希望会员服务成为他的主要的收入之一。因为Twitter以前它的收入模型非常单调，就只有广告，他现在希望是广告和会员最好一半，这样这个公司就非常的稳健。


 这个想法从商业角度来看的话是没有问题的，是对的，如果你的商业模型过于单一，而且是广告这种模型过于单一的话，其实未来的韧性是不够的。


 但是像Twitter这样的一个东西，大家已经很习惯于它的基础服务全是免费的情况下，你要去推会员服务其实是有困难。


 大家可以回顾一下我们国内推会员服务成功的是什么？这个游戏是很特殊的一个领域，咱就不谈了，搁一边在游戏以外的领域好像就只有视频的会员现在推下去了。然后再就是有零零散散的一些知识付费，知识付费的规模是不够的，视频是够的，但是视频推得非常艰难，视频和音乐现在强推什么？


 网易云音乐视频的那三大家或者4大家，这个爱奇艺是最早推会员服务推的比较好的，他的会员服务就很简单，就是广告，你如果不买惠普给你一开始看30秒60秒甚至120秒的广告，然后强推会员服务，然后一些大片的可以免费看等等这样一些福利。


 Twitter有什么 Twitter它的内容又不是自己做的，你怎么收费你总不能说我这上面最热门的推，你要看我给你收钱，然后跟推作者分账很难，所以怎么搞会员制就成了他们现在一个很大的课题。


 最新的进展是这样，艾拉马斯克想推一个服务，就是会员可以发长文和长视频，把作为一个福利，而且他的意思是我们这些推上面的意见领袖和一些商家他会有兴趣的，这一点至少我当初最早看到的时候，我的第一感是这个想法很有意思，你像在中国国内现在恨不得所有东西都是短的，视频最好是一分钟甚至30秒以内的，这个文章最好是不要超过两页，就是的两个屏幕就能看完的，最多也就四五百字，他这边现在推长了这个东西，难道在推特的生态环境里面，是要像以前老的论坛那种长文章长视频的分享去回归了吗？


 我就觉得挺有意思的，所以这个话题拿出来，我们大家讨论一下你们两位怎么看。

庄老师 27:15
 我可以举例子，在推特上面其实有一类这种视频号会吸引很多的粉丝，推特上面会发，比如说我最早开始关注的时候就是那种宠物视频。然后宠物视频它定期会转推，另外的一些视频，应该都是他们类似于营销的联运联合运营号，然后他会发什么，比如说是 almost die就是快的，就差不多要死掉的那种运气很好，没死掉的交通事故就那种视频。然后他们接着再转推，比如说是什么蠢到智商只有一的蠢货，这种干了些什么事儿，类似于这样的视频，其实一一堆的，然后我会忍不住就点再看一个点一再看一个。


 那么这种视频其实在互联网上有大量的受众，也有大量的资源，这种资源在互联网上其实有大把的，而且是在别的平台上也有很多。于是我们就会面临一个问题，假设我是多平台运营的，我在另外的平台，比如说是 Facebook或者是tiktok，我发的是超过140秒的，我要再把它搬到推特上来，我还得再剪辑，这就很烦。所以这是一个比较现实的需求。


 最好几个平台它的都没限制，我觉得都可以发。这是关于视频的，但有文章其实大家可能听说过知乎其实现在搞一个完全就开始编小说了，很多人在知乎上看到是一个提问，然后下面就有人回答，然后你看到那个回答就像讲故事一样的，还很精彩，讲着发现怎么没完，这故事怎么没完，下面有一条什么加入知乎什么VIP会员继续对阅读这个故事，它其实是一个小说小说平台，他通过第一篇就是这个故事的第一段把你吸引进去，然后你会忍不住充钱，然后开始读它的后面的段落。


 所以虽然我们在推特上面发短文，但是如果推特上面有长文，让人可以愿意忍不住去读他的故事的话，这可能也是一种商业模式。所以这两种一个是长一点的视频，不是说很长几十分钟的视频，就是两三分钟三四分钟的视频，或者是长一点的文章，甚至是转到连载小说的都是有可能的，我是这么理解的。

王老师 29:58
 感觉对奇特，也是在尝试多元化的这种商业模式。而且从现在的这种多平台运营，对，我觉得刚才庄老师提的是非常实际的一个事情。


 对很多时候作为一个内容运营者，他挺希望能够有标准化的，特别是自动化的操作，而且现在很多工具也可以这么做，你一篇文章里的一个视频可以一键发布到各个平台上面去。对，然后还可以用一些自动化的脚本去收集，然后去做这种规范化的去运营。


 因为现在这种社交媒体的这种平台还是挺多的，而且形式也还挺多样，包括除了刚才庄老师提供的，还有这种文字和视频之间的转换，他们相互之间的这种支持其实也会有挺多。


 然后其实我还看到过很多，在一个固定的渠道里面，就是把我这一周在推特上发的这些文章做一个归集，就变成了一个周报。对，然后再去做这种二次的运营和加工，对，包括后面可以做成类似白皮书，还有PDF文档，对，还有可以去用视频的方式去讲。去串起来。


 对，我感觉其实现在这种事情还挺多的，对他的这种突破和限制上的突破，对应该也是挺能够吸引这一类人，对甚至商业化的这种付费，我觉得应该还是挺有一些想象空间的。

主持人李骏老师 31:38
 目前推测对内容的长度的限制，视频是140秒，就是2分钟加20秒，然后文字的话以前是140个字符，现在扩到了280个字符，而它是字符，尤其是发英文的人痛苦不堪，英文280个字字母说不了多少东西，中文的还好一点，中文280个字真的能说挺多东西的。


 艾伦马斯克说可能会把Twitter会员的限制文字变成大概是1万个字，1万个字母的话，这个好像真的能说不少事了，平均一个英文词，我们算它七八个字符的话，那就能写1000多个word，1000多个这个词的这样的一篇文章，那是一篇小的s了，还是能说不少事情了，视频放到多长他还没说，但是他肯定说有一些长视频，国内的不论是微博还是微信，其实早就有这些东西了。


 大家记不记得很早以前马斯克刚刚说他要还没有收购，是他说要收购推特的时候他就说过，他说中国的这些微信什么做的挺好。


 所以我可不可以理解它这个玩法实际上是变相的给推特引入了公众号体系，有道理。非常像微信公众号，接下来就是说，甚至他有可能允许这些会员对自己的长文付费或者打赏，这样一来就不一样了，这样我觉得他推特整个商业模型就顿时丰满了一些，他开始有其他的金流可以在上面走了。


 如果真的是这样的话，我不说别的，就是我们在这里的我们三位有没有人兴趣去推特开公众号的？

说话人6 33:30
 可以玩玩对的。

王老师 33:31
 可以的，我也觉得可以。

主持人李骏老师 33:34
 其实我是当初微信开公众号的时候，我是非常兴奋的，我很希望这个能够成为一个百花齐放同时又对于版权有非常好的保护的这样的一个写作平台。因为在手机智能手机出现之后，其实这方面是缺失的，以前有过一些新的比较面向移动平台的一些博客的平台，但是由于各种各样的原因，他都没做起来，腾讯背后有很强的支撑，包括内容审核各方面他都很健全，他是不是可以做到这一点？


 但后面发现不是的，公众号成为一个广告平台了。


 当然你任何的写作平台都有双重属性了，一个是内容输出，一个是附带的这种广告效应，但是一般来讲做得好的话，这样的内容平台它会自然的分流出来，喜欢高质量内容的，你就去看这些内容，你可以付费订阅，你可以打赏，让他继续写得越来越好。


 另一部分就是在上面做推广，网络上比较流行的叫恰饭，我内容很好，但是我也偶尔接个广告，商务广告赚点钱，其实如果内容真的很好的话，你的受众是很乐意你去恰饭的，像b站上有很多up主，都是求着他，你赶紧做点广告，让你能接着做下去，保持更新频度是吧？生怕up主活不下去就没内容看了，这是良性循环。


 但是现实往往没那么美好，经常就变成另外一种样子，然后公众号后面现在大家已经看到了，公众号就是大量的同质内容，而且内容变得越来越快餐化，这个是有这样一个趋势。


 当然最近一两年我个人的感觉，我不知道是不是，因为我已经把它训练成另外一个模型了，我现在感觉有一些人开始反其道而行之，就是写那种很长的也很有思辨的一些文章，虽然受众不一定很大，但毕竟有一批人对内容要求比较高的人，他开始回过头来消费这些内容。


 不知道，反正这个趋势还在博弈当中，但是我觉得至少有一个平台去写一些高质量的东西，然后如果还能得到一些鼓励鼓励，不一定是打赏。如果你能够引流很多人来看，其实对写作者也是很大的支持。


 我个人的感受就是这样的，我从年轻时候到现在都是这样，我写一篇文章出去，如果能够赚点钱当然好，但以我个人的体验来讲，从来没赚到过这，但是如果有很多人看不说打赏，你看完之后你评论哪怕是争论，我都会比较开心，因为代表我写的东西有很多人看了，所以如果真的他确定了，不妨一试，至少我有兴趣去试一试，是的。


 好，关于王老师的我们就也说到这里。下面我们就开始聊我们今天的主要的话题，近期的人工智能的一些进展和我们的一些新的理解感悟。我们先来说说最近的一些进展有几个方面，第一个方面是政府和社会对它的关注进一步提升之后，那么就引入了一些可能涉及到监管的问题。


 之前我们跟大家聊过的一个就是最早的全世界第一个正式对它立案进行调查的政府，就意大利的政府，这个事情它已经有进展了，意大利的专门管个人数据隐私的叫个人数据局，他最近已经完成了初步调查，并且开了一张清单， Ok你要按这个去，你要回答这上面的一系列问题，有一些是问题，还有一些是你要照去整改，这些东西全部都搞定了，我们就可以恢复正常的访问。


 这是意大利拿出来的第一份东西还挺快的，比我想象的要快，一般这种调查都我觉得挺复杂的，复杂度主要是在于政府的那些大佬们，他要完全理解新的东西并不容易，但是他们好像还挺快的，我还没看到这张具体的清单，所以也不知道他们的方向或者是怎么样。


 因为我国也出了一份非常快的出了一份aigc的管理办法，上次我们也在我们听友群里面大家也分享过，就很明显我们国家这个是准备了很长时间的，所以里面有非常详尽的说明，包括数据来源，数据隐私的保护，还有有一些特定的数据的达标的要求等等，都有很明确的一些说明。


 我不知道意大利现在是什么样子，我还没看到这个清单，但至少它现在在往前推进了。


 然后另一边的进展就是法国和西班牙也分别对 ok的这一系列产品进行立案进行调查，但他们刚开始调查，大家知道欧洲除了已经脱离欧盟的英国以外，欧洲大陆本身主要是4个国家是主导，法、德、西班牙、意大利，现在除了德国没动，另外三个都动起来了，立刻欧盟就作出了反应，欧盟也一直是对数字化还有数字隐私保护等等这些是特别重视的。


 那么欧盟启动他就说了一个什么在欧盟这个层级他成立了一个协调的小组，这个小组就是做什么事，就是欧盟成员国如果对新的AI的发展在做调查，在做一些新的规范化的措施的时候，互通有无，你意大利做了什么？你希望他怎么做？我法国西班牙可以借鉴，然后欧盟可以把它搜集起来，也发给其他的国家参考，大家可以采用也可以不采用，如果时机成熟，说不定欧盟会推出欧盟体系的完整的建议，他们以前有很多事情也是这么干的，所以这一次他们也开始启动了，这个事就很有趣，为什么有趣？


 实际上现在在世界的最强大的这几个区域里面，大家可以看到的，欧盟是对这些事情反应最快的，但反过来他也是这些事情相对比较弱的，他很关心这个事，他实际上自己力量有限，他更多的是防御性的比较多一点。这个是我们今天说的第一个，就是我们注意到的一些新的进展。


 中国有一个aigc的管理办法出来了，欧盟的各个国家开始动作了，美国现在暂时还不清楚，我们上次提过有一个组织向美国的商务部门做了一个举报，不叫反正就类似于举报就是提交了一个申请，要调查这个事情，但是还没有正式的调查开始，很可能不会理他，因为美国还是这方面干涉相对会少一些。


 你们两位怎么看？

庄老师 40:37
 说实话还得再看看再等等看。因为在欧洲其实以前有过类似的干法直接开罚单，如果罚单成立我们就知道了。


 但是在没有罚单之前，其实你对他们没有实质的控制，现在还没有罚单，所以只能先看看。

主持人李骏老师 41:00
 这个事我估计罚单可能出不来的，因为一他现在没有相关立法，它不像之前给Google 给什么Facebook给苹果开的罚单，那些是欧盟已经很严格的立法，这几个公司触及到的立法一般是两方面，一个是个人数据隐私保护，苹果和Google的系统都有一些隐晦的灰色地带在采集一些数据，这些数据被人发现举报了违反欧盟的数字安全相关的法律，这是一种可能性，另一种可能性就是垄断。


 比如说苹果它在它的 iOS里面只有苹果官方的APP store，没有第三方的APP store，这件事情是欧盟是有非常清晰的法律的，所以苹果这个事很可能在欧盟会打破，有人说下个版本或者下个版本的iOS很可能就支持第三方的APP store，这就是欧洲干的事情，而且这个事情是好事，绝对是好事，对全世界人民来说都是好事。欧盟一旦有潜力了，我觉得中国也赶紧跟进，就是让他在这个地方屈服。这是以前成功案例。


 这次欧盟这个我觉得欧盟还没有准备好，就欧洲还没有相关的立法，所以我觉得罚单应该是开不出的，但是它可以以比如说个人隐私保护，还有数据的安全这样的一些要求，停止他在这边的数据访问。这个一般来讲他是不会硬性的去管，但他只要有这样的决定，只会了相关的公司，这公司向OPPO这种公司，我觉得他会很老实的去执行，他没必要去冒这个风险。


 所以我觉得这个阶段可能最多是到这个程度，然后甚至也很可能 open ai会比较快的去调整，来满足他的一些要求，但有些要求可能很难满足。


 比如说我举个例子，现在中美欧关于数字安全都有一个很明确的规定，就是所谓叫数据落地，你只要涉及到我们这个国家的公民的隐私数据，你这个数据只能在国内落地，这就是为什么苹果在国内必须要跟云上贵州合作。


 Apple account如果你是在国区中国区注册的apple的 account的话，这个账号的话，你的账号所有数据必须在云上贵州落地，这就是为了符合中国的监管法律，美国也一样的，美国也是规定你只要跟美国公民有关的数据不能出美国的，出美国这是重罪。


 所以比如说我以前有个朋友他在联想，联想当初收购了美国的一些产业之后，他就面临一个很有意思的问题，就是他的账号体系它到底是统一的吗？因为比如说你买了联想的电脑或者手机，你去注册一个然后登录一个联想的账号，这个账号它是全世界的系统都是同一个系统的，但是如果你是一个美国人，哪怕你居住在中国，你这个数据也必须放在美国境内，不能在别的地方有副本。


 反之如果你是中国的公民，哪怕你在全世界旅游，你数据也只能落地在中国，所以他们有一个特别复杂的账号的系统，我这个朋友就是账号系统里面做负责，他手上有大概四五百个人就做这个账号系统。

庄老师 44:18
 这东西想想都烦的要死。对，

主持人李骏老师 44:21
 这无数种情况你们碰到什么想不到。所以就类似这类问题，他都会在监管上触及一些问题，如果比如说他说你open AI采集了跟欧洲公民有关的数据，你就必须在欧洲落地，可能ok很多事情就没法做了，他可能就说算了，我就干脆只处理北美的数据拉倒。


 所以这种就有可能带来所谓的数据分块效应，这个就不确定了，如果走到这一步的话，我觉得对AI的继续发展是有一定影响的。


 所以继续观察这个也不确定，因为对政府来讲也是超级新的事情，也很有挑战，不知道怎么继续往下做。中美的态度相对比较容易预测一些，因为这都是第一是既得利益者，第二也是现在比较有竞争力的选手。所以中美的政府态度通常就会是说我一条底线你别破，有些灰色地带我现在会容忍你去赶紧做，基本上都会是这种态度。


 欧洲不太一样，欧洲的自我保护意识会更强。

王老师 45:23
 对我感觉从最近这几年的这些法律条规的制定，对现在中国在这一块的速度还有敏感度。


 我感觉还是蛮快的，包括这一次对igc的这种规制，第一个我感觉像领导人在技术这一块是明显还是挺有这种敏锐度的。


 第二个感觉时间是非常快，这就意味着是不是大家还是挺迅速的形成了一些共识，然后在一些流程部委之间迅速的推动了这件事情的落地和发布。


 对，特别是这一次的发布，我觉得还是蛮快的，快到我们可能都得去思考一下这里面的详细的一些内容和它后续能够产生什么样的一些。一些效果。

主持人李骏老师 46:21
 是的, 这次出的速度快的是有点超乎想象。


 反应很迅速，而且一方面反应迅速，另一方面我看了一些条文之后，我的第一感是挺均衡的用这么个词来说明它既有一定的底线，但是又没有任何很明显去阻碍你发展的东西。


 在推上我就看到有些人推上，我就看到有些人在嚎叫说在中国做太难了，下面附了链接说中国有一整套的管制办法了，我先讲到底有没有仔细看，这个办法里面其实除了一些底线标准，而且都是以前已经有的，比如说个人隐私数据，其他的其实没啥，所以看你怎么看这些。

庄老师 47:09
 人不看的，他其实不看具体条文的，他只要看到这个标题是某种管制意味的东西，他就会觉得它在限制发展。


 然后马上就会联想到满清什么闭关锁国，对明朝海禁什么片番不准下海，马上就联想到这种东西。

主持人李骏老师 47:28
 反正都这样。好。


 我们再来看看近期的发展的第二个方面，就是最近涌现了一种新的关于GPT的玩法，其实代表的叫auto GPT，跟这个玩意类似的有一批东西，但是目前名气最大的好像也发展的比较好的是auto GPT，要不也老张来跟我们说一说，你是最早开始看这个东西的。

庄老师 47:55
 对，但是我没玩，因为太费不起钱了。

主持人李骏老师 47:58
 对这个门槛挺高。

庄老师 48:00
 对，非常的费钱，所以我只是在网上看看别人怎么玩。最近我刚刚看到有一个新网站叫做 CoJonsys反正回头我们把链接贴到群里面，大概的意思就是说免费都能玩了，但是我还没试过，大概他的意思，其实他跟最早我们在说ChatGPT的时候，涌现出的一种能力叫做思维链有关。比如说你给他说你说我要做一件事情，比如说我要把大象放进冰箱，请问要分几步？然后他的PPT就回答你说我要分三步，第一步开门，第二步放大象，第三步关门，然后你再会问他，那么放大象要分几步，他就再把大象放进冰箱这件事情再分解成多少步。


 那么现在就有人写了一个AutoGPT的逻辑是什么？就是一个复杂事物，你就一不断的去问，就是说我要做一件事情，这件事情该分几步，第一步该怎么做，如果要写代码请帮我把代码写出来，如果要去查资料，请帮我查资料，如果要帮我搜索了以后汇总请帮我汇总，这样的一个不断的询问，然后相当于是用某种办法把GPT的能力逼到极限，而且真的有人逼到极限以后产生了一些非常惊艳的效果，当然也有些效果非常的令人耸人听闻，类似于就是说我让他帮我做件事情，然后他的AutoGPT，他就开始一步一步的往下执行，到了某一步，他开始要在网上发招聘广告了。开始招人来干活了，这个不行我赶紧把它停掉，类似于这种事情会越来越多。


 最简单的逻辑，比如说请问多少最近一个月在开源领域有什么新闻，AutoGPT就非常容易，他就开始去搜索，搜索相关的开源的新闻，然后就一篇一篇的收集完了以后汇总完了之后给你出份报告，现在都是小儿科了，更复杂的都在做，包括你让他帮你写个网站，做个程序，做个什么东西，其实本质上来说，即使是充分的利用了大语言模型涌现出来的这种能力，反正就是用到尽, 最大的坏处就是太费钱。


 我有些朋友所谓的 Token的使用量就飙升了。

主持人李骏老师 50:36
 他是必须要一个GPT4的API的访问授权，这个东西本来就比较贵，因为他是要 GPT Prime的，然后他还会以计算机的速度来调用，它不是以人的速度。

庄老师 50:51
 有人有一个比方，好比你请来一个实习生，然后你让他帮你干个活，然后他就去干了，你也不知道他能干成什么样。其实Auto GPT它每一步它可以问你，当然你也可以说你全自动就更危险了，但是他其实每一步会问你，然后你能不能允许他再做下一步，就是这种做法，所以实习生他不仅仅是说去干活，甚至你还给他开了一个没有上限的预算账户，可以直接花公司的钱去干活，这个就有点吓人了。


 对，你不知道他能干成什么样。这个是目前 GPT领域的一个比较新的发展，在github上面它的star数已经是6万多了。

主持人李骏老师 51:35
 对，而且他出来也就一两周。

庄老师 51:37
 对吓人得。

主持人李骏老师 51:38
 非常吓人。

庄老师 51:39
 刚刚看到的7万个star了。

主持人李骏老师 51:42
 对。


 这个东西像什么人现在开始在不断的试GPT的能力，试了有一些是令人满意的，有一些是令人不满意的，而且有的时候要反复多轮的去教他做一些事情，他才能逐步走上正轨。


 这个过程一般的人玩一玩，玩累了不玩了也就这样了对吧？


 但是有一批人典型的就是写程序的这批人，写程序的人，好的优秀的程序员，他是有一个思维模式的，我一件事情反复做到一定程度之后，我就会厌倦，但是我厌倦之后不是不做了，而是想办法写个程序来做，这样就不用我亲自做了对吧？


 实际上是优秀程序员推动世界发展的一个很成功的模式，现在这个模式在被应用在GPT的使用上，所以这波人就开始对着GPT写脚本，我让你做一件事情，如果结果是这样那样，那么你就这样那样把一系列的逻辑写在脚本里面，然后进一步的进展就是我启动另外一个GPT的实例来帮我自动的写这种脚本。


 大家可以理解就是很快的速度里面迭代了两步，第一步是我手工的去跟GPT去下任务，然后我就烦了，我写程序用程序来给GPT下任务，后面发现这个也很烦，这个程序经常要变，我再启动一个GPT来帮我写这个程序，去指挥GPT干活，这就是现代的AI时代的周扒皮。

王老师 53:20
 会玩。

主持人李骏老师 53:24
 这一个它相当于会有可能会让GPT的迭代会速度会上升一个量级。


 其实有点像当初阿尔法狗和阿尔法master，阿尔法狗是人类给了他很多的鲜艳的知识和体系，然后他在不断的自我对弈去提升自己的能力。然后后来进展到另一代就是阿尔法master的时候，鲜艳的也没有了，让两个围棋AI去互相下棋，然后让他们自己去总结怎么下好，怎么下才是最后的更有利一些。那么因为算力的上升，阿尔法must很快迭代成型，它的能力比阿尔法狗要强大概1~2个代差。


 AlphaGo赢李世石的时候，柯洁吹牛皮说这个AI我下不赢我，结果到跟柯洁对战的时候已经进化到阿尔法master了，柯洁就一盘都没有赢，所以这个速度当初也就是两三年的时间，就是围棋 AI两三年时间迭代到了，这一次的话可能都要不了这么长时间，他会很快的把GPT逼到他的上限，这个其实是个好事，比如说我跟老庄就一直有一个不同的对未来的判断，我认为GPT的上限是不是特别高，但是老张认为不可知，这个不确定，说不定它会很高。


 现在有了AutoGPT这种东西就可以逼他更快的到达他的上限，我就能看得比较明白他到底上限是啥，很可能跟我们两个想的都不一样，对。所以这个其实是个挺好玩的事情，我们现在要亲自去尝试, AutoGPT难度比较大，一个是钱，一个是他而且它很慢，它跑起来特别慢，就是要完成一个任务的话反应是很慢的，不像你手工去做GPT的东西。所以我们观察一阵跟它类似的还有好几个，但目前好像跑得最快的是AutoGPT。


 Ok还有另外一个玩法， Stanford跟Google也搞了个新花样，王老师给我们说说。


 好的。

王老师 55:27
 我先补充一个，对，其实和我们今天的一会讲的主角有关系，也是斯坦福的，其实就是斯坦福最近在曼塔开源的一个叫做拉玛的语言模型上面，其实又做了一个号称是最小最便宜的，什么意思？就是斯坦福做了一个70亿参数的开源模型，能够媲美GPT3.5，而且它70亿参数模型只是用了100元模型就是浮现了，然后他们把他们工作开源出来了，叫做阿帕卡。


 对，然后他们也做了一些对比和 Gpt33.5，然后包括在一些任务上面，能够赢得大概89项90项任务里面能够赢89项，这个就是他们宣称的GPT3.5的这样一个媲美。


 他们对这个结果其实非常惊讶的，而且他们也发布了整个研究中的大概5万多个问题，然后他们用来做对比，还有一些训练的，还有一些微调的代码。对是什么意思？其实感觉最近这一波开始慢慢变得能够让GBT这种技术开始平民化。就是刚才其实直接提到对，其实我们昨天有一个计算教学的会，对其中有个厂商也是在演示现场就演示他们自己搭的模型。非常慢，对，然后5秒钟才能够生成一两个字，然后过了一分钟一句话都还没有生成完。


 随着这些技术的进步，特别是像开源的这些东西的一些出来，对最近其实有好多的有一系列的都是针对 Net的开源的东西在上面去做的，然后在速度或者是训练所花的费用上，面对有了非常大的一个提升。


 对，其实一些文章就在说，现在人人都在可以有机会去用GBT这个东西了，自己也可以去搭建，还可以用一些少的成本，并不是那么高不可攀，对，我觉得这个是一个挺好的一个趋势，特别是对于我们开发者还有程序员来说，对吧？


 好，这是第一个，对。第二个就是我们今天的主角同样也是斯坦福对斯坦福最近和谷歌联手做了一个什么东西？做了一个叫做深层次智能体。对我先对这个名词给大家稍微解释一下，对智能体英文英文的单词叫做agent，本来a技能又是什么？ A技能实际上也是人工智能领域里面的一个非常经典的研究方向。


 对，那人工智能里面其实有很多的一些研究方向，对我们今天所聊的像PPT就是像自然语言理解，对吧？还有我们都比较熟悉的机器学习对吧？深度学习，还有还有一类就是智能体，对智能体也是人工智能里面的一个方向，对那个时候传统的这种智能体的研究，其实很多都是基于规则的，对，或者把一些机器学习的方法放到里面去。


 对，我想大家可能听过智能体里面的一些应用的案例，包括什么生命演化的一些实验，包括一些进化或者是模拟社会一些不同组织和个体之间的一些互动。对，它是可以用来做这样的一些事情，包括一些决策，还有行为。对深层次智能体是啥？其实就是把现在最流行的深层次人工智能技术和智能体的研究做了一个结合。


 对，就是你的智能体的这种行为和他们之间的交互，不是我们以前专家去用规则来进行编制的，而是它可以生成对用charge GPT生成自然语言理解。对，还有一些行为代码，对，然后用这些代码还有语言去做后续的一些控制。


 对，大概其实就是这么样一个一个技术背景，对生产服务这一块其实他们做的挺好玩。对他们做了个啥，他们做了一个非常有意思的场景叫做虚拟小镇。对，在虚拟小镇里面，他们就把我刚才所提到的深层次智能体，用25个AI智能体在里面做了一个模拟，对，实际上就是他们虚拟了25个a进程，然后这25个a进程里面，他们预设了25个角色，对。就是给他们预设1个角色。


 对，如果熟悉大家在玩PPT的时候应该知道我们给GDP提问的时候，很多时候可以先给他预设一个背景，比如说你现在扮演一个作家，然后怎么样对吧？对他们就这么干的，对，先给他预设了25个这种智能体，每个人都有角色。对，然后用自媒体的方式让他们自动的去生成后续指导他们行为的一些语言，包括他们之间去做一些对话。对，同样刚开始还有一些预设的一些描述，对，因为一开始的时候你必须要给他一个身份，对我举个例子。


 对25个体里面其中有1个叫做jiong，对那的话研究人员给他设置的描述是这么说的，你现在是一名药店店主，然后乐于助人，一直在寻找使客户更容易获得药物的方法。


 然后你的妻子是大学教授什么，然后他们和学习音乐伦理的儿子 Eddie住在一起，然后非常热爱家人，然后认识隔壁的夫妻等等。对他把这些东西每个25个自媒体都设置好了以后，好，那就开始开始去让他们自己让他们相互之间去沟通，然后沟通生成的一些自然语言，然后又可以指导他们后续的一些行为。对，这个研究工作实际上现在还没有经过同行评审，他们是发在开放论文系统上面的。


 对名字就是generative agent，然后什么人类的一个模拟游戏，对这篇文章一出来以后获得了大量的关注，对，不仅仅是因为爱 Idea，把这种深层是AI和agent的研究自我结合，因为他们还没有还成功的一点，就是他们的那个例子是非常有意思的，就是25个智能体在一个虚拟小镇，而且他们虚拟小镇它是用了一个类似我们游戏里面的rpg的那种风格去做的一个实际的绘制，然后他们也在网上公布了一个可以试验的链接，就是你你打开网站以后，对我们节目里面一会可以把它发出来，打开那个链接，然后你选择一个角色，然后就可以用一些规则，然后就可以运行，可以看它去做一些演化。


 对，这里面其实就非常像什么像西部世界对吧？

说话人6 01:03:12
 对，我也想到西部世界里面对一些场景。

王老师 01:03:16
 对，因为这个工作还挺早的，反正现在很多的一些讨论，包括他们自己也在聊后续能够做些什么事情，是不是能够真的像我们所提提到的能够有一些比较涌现的东西出来，包括我们自己也没有看到的。对，我是觉得这个还还是特别有意思，我们后续也可以持续去关注这件事情，这个是我的分享。

庄老师 01:03:43
 这个想象空间就太大了。


 对。


 一门新的学科我觉得都是可以建立的，比如说叫做模拟社会学。

说话人6 01:03:55
 或者叫对社会学。

庄老师 01:03:58
 因为。

说话人6 01:03:59
 社会学。

主持人李骏老师 01:04:00
 本来它就长期以来都在使用类似的研究方法，现在只是这个研究方法，它如果真的能够借助生成是AI来实现的话，它能够避免以前这个方法里面的一些弊病。


 以前这个方法里面的弊病就是参与的实验的人，他没有办法完全按照实验者的设定来工作，它会有很多噪音，就相当于如果是我们理工科的研究的话，就相当于数据噪音，社会学的研究里面，它这些噪音就更难识别一些。


 如果说是真的能搞成像西部世界那种东西的话，它就是可以做很多非常严格的定义化的和定性化的实验。

庄老师 01:04:46
 甚至有一些我们可以去做所谓的政策模拟，什么政策先模拟运行，就在虚拟小镇里面运行，然后看看他最后老百姓是啥反应，这个想象空间太大了。

主持人李骏老师 01:05:01
 他现在只是25个，如果他能扩展到比如说25,000个人的话，那就能搞很多的事情了。当然还是我个人觉得可能还是一个起步阶段。

说话人6 01:05:12
 还要再看。

主持人李骏老师 01:05:13
 因为这个会产生连带的问题还挺多的。很可能搞一阵子之后不是触发一两个新理论了。

说话人6 01:05:23
 可能会。

主持人李骏老师 01:05:25
 他会提出很多问题，然后这些问题里面就会诞生很多新的学问。反正这个事儿。

庄老师 01:05:31
 有些学科就要翻篇了，或者甚至就被颠覆掉了，都有可能。对。

主持人李骏老师 01:05:35
 然后就会产生很多新的学科。

说话人6 01:05:37
 对。

主持人李骏老师 01:05:37
 这个是非常有意思的，如果只停留在写程序这个角度的话，虽然我们这些程序员们很开心。

说话人6 01:05:44
 但是他。

主持人李骏老师 01:05:45
 的社会影响还是有限，但是到这个层面的话就不太一样，这方面不得不佩服美国人还是搞这些东西是非常的有灵感，而且敢搞敢做。

说话人6 01:05:55
 是的。

主持人李骏老师 01:05:57
 我觉得我们国内的相关部门可以牵头学起来，这事中国人做起来只会更容易蛮适合。

王老师 01:06:05
 对也蛮适合来做的。

主持人李骏老师 01:06:06
 包括而且其实符合我们现在的政策导向。


 我们现在谈数字政府已经谈了很多年了，我们在很高层的级别上做政府的大数据和AI辅助决策的尝试，已经有一段时间了，其实我们的高层很重视这个方向，因为跟反腐有关，我们现在的逻辑很强调所谓的怎么击败历史周期律，然后最后的结论就是反腐和自我革命。


 人的劣根性，人的本性里面恶的部分是很难消除，对不对？怎么消除呢？大数据和人工智能辅助这是一个挺重要的分支，其实好说到这个我前面不是跟大家说，我们刚刚给我们的音频的服务器搬了个家，所以这个过程当中我也把以前老的我们的各期的节目也都看了一遍，这个老庄正好也在回顾以前老的一些节目，然后我们就发现其实我们第一期节目就聊了一个跟人工智能有关的话题，当时讲的是阿尔法扣的。

庄老师 01:07:17
 现在都想不起来阿尔法扣的是啥了。

说话人6 01:07:20
 对，我要回忆一下。

主持人李骏老师 01:07:23
 那是啥东西。我们一年多以前聊的，然后当时王老师还说了，说这个东西对我们一直很关注很想做的计算机学名教育是有关联的，而且很可能对有帮助，那个时候我们对AI发展的很多判断，其实跟现在又很不一样了，而且我们那个时候根本无法预测到后来的AI的到目前为止一系列的发展。我发现没事回顾一下以前我们自己讲过的东西还挺有意思的。所以今天我们再来说一说跟有关的话题，当时我们怎么看待AlphaGo的这样的一个系统？现在的a跟它比起来又有什么样的变化？


 是不是也对我们很关注的，比如说计算机全面教育有全新的一些可能性或者一些全新的认识？王老师怎么看？

王老师 01:08:16
 我先说一下，对我也稍微回忆了一下，然后查了一些东西，就是像aaah barkow的和我们现在的chart GPT，对它里面其实可以有一个共通的地方，如果在编程这一块，其实他们都是可以做编程自动化的一些工作的，对不对？而且这两个工具它的背后的技术原理其实是非常高度一致的，都是利用大别模型深层次的技术来去做这种代码生成，对，当然他们有不一样的地方。阿尔法扣的它的重点应该是在扣的，而且它主要是编程的那种语言，还有学习，然后生成。


 对 Chat GBT的它的重点应该是在chat这一块对吧？然后明显的是可以进行多轮对话，然后如果你是在涉及到编程的方式，它就可以给你输出编程的一些模式。


 我觉得这个还挺有意思的，当我们前面说到阿尔法code的时候，对对，它可能更像是一个专业领域的代码生成工具。对，就是因为他只是专注在代码这一块，对，所以说当时能够产生的一些效果，包括在一些编程比赛里面取得的一些成绩，对你同样也是非常惊艳。所以说使得我们当时是一下子就能够关注到。


 对，所以说我们当时也在畅想这个东西，等他能够和学校的编程教育进行结合的时候，其实能够大大提高，比如说做一个老师的助教，或者是老师的或者是学生的一个编程助手。对可以达到提高到它的一个编码效率，对，包括在职场里面也是可以。


 对，恰恰GDP的这一块其实感觉的延伸度又更宽泛了。对，它不仅仅是可以做到 AlphaGo做的事情，对，当然这件事情其实有争论的，有一部分说 AlphaGo的在专业度这一块还是要略强一点，但是明显可以看到像charge PPT的这种人际对话模式，使得他能够做的事情要大大的它的空间要大大增多了，对，包括我们刚才所提到的，你甚至可以只会一个掐了GBT去和另外一个家的PPT去交流，指挥他去做一些事情。


 而且自然语言的这种门槛其实是大大的拉低了。


 对。不光是在编码场景，你可以在设计场景原型场景，甚至一些营销场景，对吧？里面都可以去用，这样的话你其实更是一个这种全站的这样一个一个人，并且能够把这些自动化的工具在这些不同的环节里面都能够用起来，包括甚至整个软件工程。


 对，我觉得很快的就让我们进入了一个类似新的世界，对，包括它能够支持我们教育里面能够做的教育的事情，从比较窄的编程的这样一个小的场景，能够几乎复制到所有的课程里面去，包括一些实践，对吧？


 我感觉这个还是变化太快了，我现在说这几句。

主持人李骏老师 01:11:52
 其实我觉得其他GDP跟阿尔法扣的它类比是比较难的，因为它不是一种东西，实际上跟are Ferko的比较对应的是OPPO a的另外一个东西叫codex。

王老师 01:12:04
 code ess。

主持人李骏老师 01:12:06
 codex是copilot背后的模型，所以我觉得AlphaGo zero的它对应的是copilot和codex这个东西。


 叉PPT是什么概念？叉PPT我认为实际上是 openai把它的a的成果，尤其是大语言模型上面的成果把它整合到一起，然后通过一个自然语言的人机界面推出来的方式，所以恰GP的背后肯定也接入了cos这样的东西，就是恰GP可能是有好几个不同的东西把它揉合在一起，然后用一个统一的对外的界面，这个界面是一个就是我们现在的人机界面是人类鼠标点击或者是输入一个什么命令，其实我们跟机器人打交道是这样的对吧？


 下GDP开创的一个全新的人机界面就是。

王老师 01:12:59
 自然语言对。

主持人李骏老师 01:13:02
 所以为什么我们觉得掐PPT会非常的不一样，它其实就在于替换掉了我们日常使用的所有的其他的这些人机交互方式，而转为用自然语言给电脑去发命令。然后它如果这个命令是关于编程的，它后面它自然会去调用，比如说codex相关的能力来完成写程序的工作。但为什么最开始抠拍了它的效果没有那么好，其实是因为我们在告诉copilot做事情的时候，自然语言它的理解跟不上，好到 GPT3.5和GPT的时候，对我们的指令的理解比以前更好了，然后到4又有了一个新的飞跃。


 实际上说白了是计算机理解我们的意图这个层面上在提升，也就是在人机互相理解的界面这个层面上在提升。而具体写代码这个东西可能最后还是落地到口口x这样的技术，而cos这样技术跟阿尔法扣的我觉得实际上是一个level了，它没有很明显的察觉。所以回到刚才说计算机全民教育的话，那是要教育这个话题，我们说我们在做教和学的工作的时候，它具体涉及到的那些技术，其实没有产业里面使用的那么深那么广，他甚至只要举一些合适的例子就可以了，他不一定要做那么深入那么具体的分析。


 所以教育里面人和人之间的语言交互和这种深刻的理解，反而是一个更有挑战的事情。


 举个例子来说，有的学生他做一道题做错了，然后老师去问他你为什么会做错呢？学生自己当然不知道自己为什么做错了，他可能会说我粗心，或者他说我没看清楚题目，但是有经验的老师和没有经验的老师，这个时候就会有非常大的分水岭，有经验老师会看出来说，你其实根本不是什么粗心，你就是某个关键概念没有理解，对，那没有经验的老师呢就分析不出这些东西来，他就也会简单的推论为你粗心了。


 所以为什么我们经常会看到说这孩子别的都好，就是粗心大意，其实那么多粗心大意，绝大部分真实情况是它就是某些关键概念没掌握，但要识别出这一点是不容易的，这是教与学里面一个很大的挑战。计算机做这种事情当然不是靠经验，它是要靠一系列的试探跟你的来回的往返的一些交互。计算机会问你一系列问题，你这个题做错了，这个地方你怎么理解？它会把这个题目的解答拆成比如10步，每1个大的题目会拆成10个小问，每一问去考察学生的1个关键的理解点，1个掌握点10个问题下来就能够给出1张很清晰的诊断，说这个学生他就在某个知识环节是没掌握好的，需要强化给他几个题目专门补这个环节，其他几个掌握的是好的。


 这种分析在教育学里面测评学里面是关键的研究主题，所以我觉得为什么之前我说咱们要把 Ai应用到教育里面，需要一些定制化的开发，其实就是指这种类型的开发，这个是要计算机从头开始自我发现一遍，好像挺困难的，所以需要有一些指引，然后但是基本能力他现在已经具备了，这个是我的一个感想，换句话说可能是我现在跟我们第一期节目的时候相比，想的更清晰的一些部分是这样的。


 老张怎么看？//

庄老师 01:16:53
 我有一个大的猜想，也是涉及到我们前面在说到吴军的事情，吴军对于大语言模型最大的一个误解，他还是按照这些 AI的分门别类的能力去理解大语言模型能干什么不能干什么。


 但是其实我们最早用AI来模拟人的时候，其实是想模拟人脑的，人脑从来就不是说我有什么分区什么，它其实到后面都是混在一起的这些能力，一个人脑就有这么多能力。


 那么现在到了大语言模型的 ChatGPT以后，我们也开始发现了一种叫涌现的现象，一个模型它能够涌现出多种能力，而且它可以混在一块用，你可以在一个问题里面，既让他思考逻辑，也让他写代码，甚至还让他最后给你一个综述都可以，那么这代表着什么？代表着其实很多能力，我们一开始人就是人类想要去模拟 a就是要想用AI去模拟人类智能的时候，一开始觉得事情太复杂，我只能分别处理，到后面也许我们最终就把它混在一起，一口气全给它端掉，全解决了。


 这产生一个什么联想，就是在教育里面，我们现在的教育说到底还是分科教育，分语文、数学、计算机，然后甚至再分编程语言，什么c语言，Java Ruby 分开教育。那么未来有了AI，有了大语言模型的AI辅助的教育，是不是分科就不再重要？这是第一个猜想。


 第二个猜想就是人和AI现在就是说我们说是一个学习的团体，是三个角色，老师、学生、AI，如果这三个角色组成的是一个有机的整体，他们怎么样共同学习？不是说我以 Ai作为工具，我去教学生，也不是简单的说学生用AI来工具来自学，而是假设他们三个是一个共同体，他们怎么互动？会发生些什么？就在这个当中AI能帮上什么忙，他可能也可以帮老师，也可以帮学生，甚至它可以帮一个团体。


 就是当我们去想象一个未来的教学的时候，可能不是在现有的教学模式里面想想这里加一点AI，那里加一点AI，而是就像是两个人的家庭变成了三个人的家庭一样的完全变掉，我没想好，我只是随便联想。

主持人李骏老师 01:19:35
 这两个问题我觉得是这样，首先第一个大脑是分区的，这个是有生物学上的大充分的实验的判断的，对它是有功能分区的，而且是互相协同的，所以我们直接去模拟大脑，我觉得挺难的，这条路基本上很难走通。


 然后在教育里面为什么要分学科？这个并不是我们从教的角度出发要去考虑的，而是从学的角度，分学科是为了让学习本身变得容易一点，就是你在一个学习的角度，你当然希望你学的东西越简单，越单纯越好，因为人不可能像电计算机那样，一下子把无数的数据灌到你脑子里面去，然后过一段时间之后，你脑子突然就把它从里面涌现出了各种各样的能力，这个不是人能够工作的方式，所以设计分学科，我觉得更多的是让学习本身有一个进度，有一个学习的顺序，或者说让你同一时间内学的东西是相对单纯有限的，这是为了人考虑。


 如果人的大脑不能做到说脑机接口直接接一个外部协处理器的这种程度的话，这一点就很难改变，因为人的思维模式受不了那样的大数据灌入的这种模式，所以我觉得分学科更多的是设计学习路径的问题，所以我觉得好像短期内比较难改。


 第二个我完全同意 AI它还是工具，但是工具怎么用，不是简单的就是在原有流程里面局部改善，它应该是可以有一些更创新的方式的。但不管怎么改善，它都有一个问题在哪，对它有相当的严谨性和准确度的要求。


 这一点我们下面最后这个话题里面是会提到的。当我们使用AI作为助手的时候，我们对它的容忍度其实针对不同的问题集是有区别的，有些场景下我们不追求它很严谨，我是在反复不断的去试，偶尔试出一个好的结果，我就很开心了，这是一种应用场景。另一种应用场景是我容忍度非常低，你不能够老出问题，你的可能出问题就是百分之零点00几才行，得给我4个9, 5个9的可靠度才行。


 教育是要求是相当高的，可能至少得是百分之九十几的可信度才行，否则误人子弟这个玩意儿会很麻烦，而且你一旦把它批量使用之后，是大范围的误人子弟，这个就很可怕。所以这个里面的话怎么去用好它，我觉得是有很多方法的，当然是在教和学两端都可以，比如在教这一端，它可以帮助我们去做很多老师做不过来的工作，比如助教, 刚才王老师提到的，老师上完课之后，不同的学生会有不同的问题，那么AI去回答这些问题，这个马上就能够体现出来的一个好处，但是怎么做到这一点，这回答问题不能乱回答，要相当高的正确率才行，这是一种学的层面也是的。


 比如像我刚才说的自我诊断，学生考完试了或者学完一个单元了，那么通过AI来做一个自我诊断，知道自己学的状况如何，然后去做相应的增强练习，然后再来一次诊断，发现自己提升了，对学生的激励效果是非常明显的，这叫做自反馈。


 教育里面的自反馈是我个人认为是最重要的一个环节，它既能激励你不断学习，继续学习，它也能够提升你学习的效率，就是你不用在你已经掌握的事情上面浪费时间。同时你每一次做了一点什么事情之后，去做一下自我评估，发现你提升了，这个时候你的动力就会很强，这个都可以借助AI来实现问题是怎么做到这一点？


 这个是要摸的一个过程，我觉得是现在还悬而未决的，因为现在的AI它确实挺好，但是能不能做这些事情，也没有人能够真正系统性的尝试过，没有尝试过的一个很重要的原因就是目前这个技术还没有完全开放，他还掌握在少数人手里，他没有办法大范围的去尝试。


 比如我们想做一个深入的相关教育的实验的话，没有这样的基础平台给我们去试，所以为什么最近其实有好几个开源的体系正在出现，比如说有一个公司叫data bricks，他就做了不少的开源的模型，虽然它现在规模还不是很大，它现在比较大的模型是百亿，这个数量级就是100亿个参数这个数量级，跟现在那几个千亿和万亿级的还是有一定差距，但是不代表它做不出可用的东西。


 比如刚才王老师也提到 Stanford做的一个就几十亿个参数的，它的效果不差，说明有一些fine tuning，有一些精调的工作之后，不那么大规模的，甚至在个人电脑上可以部署的一个Lm，它也许在特定问题上就是可行的，我们现在人类还没有搞得特别清楚，所以但这种是完全开源的，比如说他们搞的叫Pythia这个模型基础之上就有很多人因为它是开源的，所以就有很多人在这个基础之上去做了进一步的精调，然后出现了不同的东西。


 比如他们自己最近做了一个叫Dolly, Dolly2.0，这个上面它也是一个百亿级参数的模型，但是他们现在测试的效果觉得还可以，因为它完全开源，所以很多人也开始玩它。这个说白了当年安卓跟iOS打架的原理，就是你很强大，你领先很多。


 当年Jobs在推出iPhone的时候，说iPhone的硬软件一体技术至少领先5年，他这个5年说的太精准了，2007年iPhone出现到12 13年正好是安卓跟iOS水平追的，基本上到一个level的时间就靠开源，所以我现在挺看好他们这个方面的一些前进，还有今天早上我看到一个新闻叫open assistant，他的目标就是做一个完全开源的ChatGPT，他刚开始做，所以他这个东西还没有办法很成熟大家去试，但是为什么有一些人看好，因为它背后的这家公司它是专门做开源的这种大规模的数据模型的那些基础数据的一家公司，它是一个开源的组织，叫拉laion, 缩写, 这个缩写的意思是largescale artificial Intelligence open network，大规模人工智能开放网络组织搜集了很多跟这些大规模模型有关的一些数据，然后现在开始要利用这些数据来做这么一个完全开放的ChatGPT, 他们也刚刚起步，说不定还不如我们百度现在的状态，但是因为它是开源的，所以我觉得给到他们。

庄老师 01:26:52
 李骏我汇报一个数据， open assistant 现在的github上面已经有2.2万个星了。

主持人李骏老师 01:27:00
 对,太吓人。

庄老师 01:27:02
 昨天开就。

主持人李骏老师 01:27:04
 十几个小时，不到24小时就有2万多个星，这就是open source的power，就是你再好我用不上跟我没关系，你哪怕是个baby，但是我可以参与进去，那就不一样。


 所以我觉得国内的几个大厂商现在都在推自己的Lm，这是一条线，第二条线是开源这条线，如果这东西都起来的话，可能很多东西我们就可以去试了，说不定就能回答刚才老庄说的那些问题，具体在教学的过程当中怎么用进去是最好的。


 这个需要教育学的专家，计算机的专家，还有一线的老师们，就是要一起来做这个事情才行。


 Ok我们顺便过渡到我们最后一个话题，到底它能够和应该怎么去帮助人类？我个人的一个观点我先说一说。我现在越来越有一个体会，就是不管现在的AI怎么发展，甚至在可预见的未来几年里面，都更适合作为一个assistant，而不是一个delegate。就是你可以把它当助手，但是你不能把它当做一个完全的委托，就是你把这件事情完全扔给他，甩锅不管了，他去搞定。哪怕现在AutoGPT就是这个目标，就是让他自己去指挥自己干事，遇到错误自己撞墙了，自己去调试，我觉得挺难的。


 为什么挺难的？就回到我刚才说的人们的工作它是容忍度是不一样的，我举个例子，最近我感悟的玩游戏感悟出来的，其实人玩游戏是有不同的玩法的，比如最近我在玩个游戏叫卧龙，这是一个有一点难度的动作游戏，就是你要去打怪的打怪这些怪都很厉害，你要练习你才能打赢他们，不是那种噼里啪啦就是无双横扫的，这是属于那种有一定的动作门槛的游戏。


 那么玩这个游戏我是怎么玩的，我就是慢慢打，对吧？死了重来，在死当中去不断的学习成长。然后你死的过程不光你可以练你的技术，你还可以积累一些装备，你装备上去容错就高了，你对方打你就没那么疼，本来是一刀砍死，你现在两刀甚至三刀都砍不死，你就有很多机会喝药，然后继续。


 这种玩法的好处就是我总能过关，我打了100多小时了，这个游戏已经二周目打完了，就是先通关一次，把所有东西都搜集齐了，然后它就会提供一个新的难度，更难的难度，然后你打新的难度又打通一遍，100多个小时。


 然后最近我还发了一些视频到b站上，你去看那个视频的话，你会发现李俊好厉害，打的老怪无还手之力，一分钟就把他干掉了，非常的爽。


 但是你不知道我其实死了十几次才得到这个效果，对吧？你反复试，总有一次你发挥的好的，他发挥的不够好的，你就过了。这个乐趣有没有？当然有，我传视频的时候爽死了对吧？我就很开心，而且我打这些视频的时候，我的装备已经相对来说是所谓毕业装了非常好的装备了，伤害也很高，防御也不错，这是一种玩法。这种玩法有没有乐趣？很有乐趣，而且也没什么压力，没什么负担对吧？


 好，还有另外一种玩法，叫速通，所有这些游戏都有一种速通的打法，叫speedrunner，就是我以最快的速度打通这个游戏，然后有一个世界纪录，大家都去竞逐这个世界纪录。现在卧龙这个游戏世界纪录速通的世界纪录是多少？我打了100多个小时，他们现在速通的记录是1小时27分钟。

庄老师 01:30:45
 好远。

主持人李骏老师 01:30:47
 就是一个半小时以内可以把这个游戏打通。他打通的办法，首先他会跳过很多内容，很多他都不打了，直接跑过去，通过特定的路线或者特定的方法还有跑过去，然后直到最后去打boss。


 但这样的打法的问题是你过程当中都不打，你没法升级对吧？你也捡不到很多装备，你只能用很初级的装备很低的等级去挑战一个很强的boss，对你技术要求很高。


 好，而且还有一些boss他的是有随机性的，他一会出招一会出招，出这个招可能比较好，挡出招就很麻烦，如果可能的话，你最好能够限制它的随机性，就是你最好有一套办法上来就按照套套路，然后 Boss的出招就会相对比较可控，这种就叫定番，按一定的路径就可以一定打过他的这种最好，但有时候没有只能考你的技术和运气了。


 好，那么在speed run在速通的打法当中，对稳定性的要求是极高的，一个半小时你可能达到一个小时，突然出了一个小错误，你就挂了，挂了之后你就不可能破记录了，你只能从头来。所以在速通当中你选择的装备，你使用的武器，你使用的招数，然后你跑这个图的路线，以及你打boss的方法都是尽可能稳定，它的容错是非常低的。


 那么现在我们回过头来说AI，那么我们对AI的要求是什么？我们现在很多人在玩ChatGPT或者玩GPT 4的时候，他都是按照我刚才说的第一种心态去玩的，他就随便试试玩一玩，偶尔有错误胡说八道无所谓，我就忽略掉就行了，但他偶尔有一个很惊艳的结果的时候，我就很开心把它上传，然后就完成了我的循环，我就很开心这个事就这样了。


 但是你真正在做事的时候，当你想把它应用到你的日常工作当中去的时候，其实你的容忍度就会飞快的下降，你就不能接受这些东西了，你就需要他在尽可能快的时间里面尽可能稳定的提供好的结果。这个时候你对AI的认知和想法就不一样，对他的要求就完全不同了。不光是教育，还有你日常的工作。


 这个时候我觉得这个会有一个相当的过程，他没有办法很快的从第一个路径变到第二路径，比如我可能一辈子都不会去尝试速通，因为我知道我很手残，我没那个本事。打速通的都是很有天赋的人才可能去做，当然我也可以玩玩试着玩，模仿他们的路径去玩一玩，那就不可能追求世界纪录了，我就随便玩一玩死了就拉倒。


 所以我觉得是我们现在去看待 Ai怎么去帮人做事的时候的一个需要提醒自己的一个点，你们怎么看我？

王老师 01:33:50
 先说我最近有一个感受，其实在用这些智能工具，其实给我最大的一个帮助是啥？能够有很多的这种启发性。对，比如说我在想写一些内容对吧？或者是准备一些课程，对，包括现在看到别人甚至一些图，对，因为图这块的话我还没有尝试太多对它给我带来的一些帮助，其实就是给我带来很多的一些可能性。


 对，因为我自己的一些阅读阅历这方面的一些有限，但是像GPT的这种生成模式，其实它是和全球至少很大一部分的这种语料和他们的一些内容去生成的，至少给我带来了很多的一些策略，包括我想不到的，对或者是我想到的，但是一些细节我也不清楚的，对，他可以给我很多这样的一些启发，有了这些启发以后，我可以去深入的再去做一些核对，对吧？然后可以去做真实内容的这种写作生成。对，但是它这种启发性其实我还是挺喜欢的，我为什么有这样一个感觉，是因为我不知道大家用谷歌搜索引擎的时候是怎么用的，我也挺喜欢去用搜索引擎去，甚至有时候去漫无目的的去搜一些东西。


 对我简单来说，以前我们收论文，论文的时候就是你输了一长串的关键词匹配，对他除了会给你返回那一串关键词匹配的非常具体的链接下载地址以外，其实它还可以给你很多相关的一些文章，虽然不是语义上相关的，它可能就是从关键词的形态上去做一些相关，但是即便是这样，你也可以从里面比如说翻个前10页，甚至可以淘出或者是找到一些比较有意思的内容，这就是我所谓的他会给我启发，但是可能是会比较有一个耗时或者是费力的。


 对，有了ChatGPT以后，我感觉它的这种效率甚至会更高一点。


 对，他也许是胡编乱造深圳出来的，但是你只要去核对一下，你是可以很快的去做一个筛选掉，但是确实是能够他编的东西，即便是他编的，有时候也是可以给你一些启发的，比如说你想做一个选题，对吧？或者是你想关联某个领域里面的一些相关的知识，他编的还挺有启发的，我觉得这个也是能够给我一个很大的帮助。


 对，所以说我还挺愿意把它作为一个启发式的这一类工具，即便是他不断的唠叨唠叨，有对有错，但是是可以给我有不断的这种创作上的启发。


 对，这是我反正最近有一个挺重要的感受。

主持人李骏老师 01:36:52
 我觉得我们可以做一个事儿，我们来推荐一些在很严肃的场景下，真正有帮助的AI的用法，不论是不论是 Learn by AI还是work by AI，就是用AI来帮助你学习或者帮助你工作的过程当中，不是我刚才说的那种比较休闲的玩法，而是真的正儿八经可以产生生产力，而且可靠性有保证的。


 比如我举个例子，你写博客的时候你需要一些图片，这个图片你又担心有版权的问题，那么你怎么操作可以生成你需要的图片，这个是很多人验证过的，而且完全可行的，这一定能帮你提升效率。 Ok这种就是一个很好的 case，对吧？还有刚才王老师说的叫启发式讨论，其实说白了你跟人聊天，而且你跟人家聊天的时候，相当于你跟很多不同风格的人聊聊天，这些东西不是你立刻用在你的文献里面，但启发你思维这个一定可以一定ok。


 还有最近我看到有一些人的实力，我觉得在写代码这个层面上，有一个我现在觉得比较可靠的写单元测试，你换一个程序给 GPT 4，然后告诉他说你帮我里面的这几个函数写 unit test，好像我看到的实例基本上还挺靠谱的，就类似这种它一定可靠，一定可以立刻拿来用，一定可以放心的去用，没有问题。


 我觉得是咱们去开一个开放的协同列表来登记这种idea，我觉得会挺有意思。

王老师 01:38:37
 我们开个。

庄老师 01:38:38
 项目好了，现在已经有了，有一些wiki就叫做提示工程。

主持人李骏老师 01:38:45
 我看到过，但是我觉得那个里面很多完全达不到我的标准，或者不够常用或者不够可靠，这个没关系，反正我们可以去搞。

庄老师 01:38:59
 我现在用法是这样的，第一个是我用它来替代翻译。

主持人李骏老师 01:39:04
 这个绝对可以对。

王老师 01:39:06
 很好的场景，这是一个。

庄老师 01:39:08
 对，而且我会要求他比如说我在读的是一一本正义论政治哲学类的书，我就直接说请按照伦理学政治哲学类的风格来翻译，他就会特别关心关注到一些关键词，它就不会乱来，这是比一般的翻译要好得多。

主持人李骏老师 01:39:28
 Machine translate就Mt，这个是machine translate很有意思，它是整个自然语言处理这个领域里面的称为叫做试金石。


 大家评判我们NLP发展到什么阶段了，就看机器翻译做到什么程度了。我个人经历过的上古阶段，那个是一个阶段，然后一个标志性的变化是 deeply， deeply出来的时候，我觉得是一个第二个阶段，DP可以在不复杂的上下文里面做到相当好。


 然后现在 GPT4 为代表的，我觉得它是更多的融入了复杂的上下文和一些风格性选项, 这个方面是GPT现在还没有的，所以可能在现在相当于是2.5个阶段, 什么到第三个我不知道，第三个可能真的能够像人的翻译，更像人的翻译，反正现在的翻译我觉得这个是非常实用了，比绝大部分人做的好，对的。


 第二个就是大量的书都翻译的很差。

庄老师 01:40:34
 第二个他会帮我拾遗补缺，比如说我最近想写一本开源相关的书，然后我就说我现在有一个提纲，你帮我看看怎么改进，他就会帮我再加一些东西。我一看我在提纲里我没想到挺好的，我可以把它加进去，这是一个我跟ChatGPT直接聊的时候，他会给我补的东西。


 另外就有人基于这样的东西做了一个叫AmyMind, 也是一个脑图，它的玩法是什么？就是说你先创建一个节点，你本来是自己手工的加子节点，但是你现在可以让AI帮你家直接他就给你飕飕的给你加了一堆子点，你可以一层一层的往下加。这些都删掉对不对？就最多删掉，但是它会非常的有启发性的帮你补上一些东西。

主持人李骏老师 01:41:29
 这个可以, 作为刚才王老师说的这种启发式交流里面一个具体可用的工具，它进一步细化了，而且工具更加特化，越特化的工具越好，用，这个是一个经验，所以你刚才说直接用一个脑图的方式，这个挺好的，它很适于结构化，然后最后怎么用它，那是你自己的事了，挺好，所以你看我们与其去争论他的上限，不如看他现在能够做的事情，哪些立刻就能很可靠的帮我们，这就非常有意义。

庄老师 01:41:59
 还有第三个工作习惯的改变，就是现在我干点什么事儿，我都会有意识的去想想我能不能用ChatGPT来干，或者是类似的相关的，或者是看看别人有没有已经琢磨出什么新的方法来。


 本身这就是一种工作方式的变化, 它会发生巨大的不同，越来越多的人就会去探索，你现在不能够假设他只能干3件事，5件事你试试看，不行最多自己再干。

主持人李骏老师 01:42:32
 这个是非常体现用我们现在流行的讲法叫非常体现数字素养的高低。


 老庄现在这个思维模式就属于有很高的数字素养的人的思维模式。


 素养不够就不会这么去想，他不是很热衷于使用新的工具，而且比较害怕使用工具的失败，这个就需要去试试，完之后总结，然后更多的人敢于去使用，这是有个过程的。


 好，我给大家补充一个很有意思的案例。


 最近美军做了一个测试，美军其实现在他们美国的军工产业最近这10来年非常有意思，叫做软强硬弱，什么意思？就是他们的硬件能力越来越差，因为去工业化很多东西想做不出来了，你像最近什么登月的火箭的事，还有他们高超音速导弹试验，最后失败，一整个方案完全放弃掉的事情，都是跟硬件工艺有关系的，但是软件还是很强，这方面不得不承认他们软件依然非常强。


 好，他们怎么玩软件呢？就是用AI来辅助战场。最近他们做了一个一系列的测试，是用AI来帮助空军战斗机的飞行员在复杂的战场局面下做出决策。他们改造他们几个很常规的f16的战斗机，然后把他这些AI系统给他们串起来，然后尝试了很多不同的AI算法，在不同的场景下不同的算法提供不同的方案，这个没什么，他们已经测试了很长时间了，说不定我们这些测试只是没有公开，但他们最近做了一个有趣的测试，我为什么觉得特别有意思？


 是这样的，他们在测试一个什么东西，就是测试飞行员对AI的信任程度，他体系它设计成这么一种状态，就是一个高度智能化的助手，但是它不替代人，还是让人来做决策。就像前些时我在群里面分享过一个我们解放军报登的一篇关于AI的科普文章，文章写得相当好，我觉得比很多这个科技业的人写的都好，非常严谨，而且也没有什么很夸大的东西。


 里面结论是一样的，最终主宰还是人，但是AI可以提供很有价值的辅助。


 所以你可以设想就好像你在驾驶一架战斗机的时候，突然 Ai灯亮起来了，表示他有一个建议，你可以听他的建议决定采纳不采纳，甚至你可以不听直接采纳或者不采纳，他是这么一种状态，最终决定权是人。


 好。那么他最近美军做了一个测试，就是在各种不同复杂的空情下，然后测试不同的飞行员对于AI的信任程度。其实现代空战非常复杂，如果有比如说玩过一些拟真度比较高的空战游戏，比如像王牌空战这种的话就有概念。


 其实你一个飞机飞在空中，它是三维立体的，上中下前后左右全都可能有方的和敌方的飞机，然后每一架飞机上有非常多的传感器在给你灌数据，有各种雷达，电磁波的雷达，光电的红外的雷达，还有你目测到的一些东西，对吧？


 还不仅这样，还有所谓的数据链，就现在战争非常复杂，在一个战场体系里面有很多东西都在搜集数据，不光是你自己这架飞机，你的友机有数据，这些数据是通过数据链连在一起的。


 还有卫星的数据，还有战场上通常有一个头上顶着个大盖子的预警机，大盘子是一个大的雷达，它也会有很多，还有地面和海平面上面的，比如像我们很强大的055就是指挥舰，它也会有一个中心指挥系统也会给你扔数据。


 所以其实很复杂，一个复杂的情况下，你肯定很多选择发射导弹打对方，别人锁定你了，你可以扔一个干扰导弹，然后你可以通过特殊的机动来摆脱对方的追踪，各种各样的判断选择。


 然后在这些复杂情况下，测试 AI提出的建议，提出建议之后，飞行员采纳不采纳？他们最近测试的结果看了非常有意思，它这个结果表明什么？越是非常老的很有经验的飞行员，在越是复杂的空情下，越倾向于相信AI的建议。


 这个结论我看了觉得特别有趣，就拿出来跟大家分享，就这个阶段属于那种一看觉得怎么会这样很奇怪，然后再想一想觉得好像又挺合理的，你们怎么看？

庄老师 01:47:20
 简单的说越是没经验，越是自信，越是江湖老，越是胆子小，这个话都是这么说的，不知者无畏，对。

主持人李骏老师 01:47:32
 而且这些老兵他们其实我倾向于猜测，我也不是空军，我只是猜测，其实跟我们写程序什么也有点类似，越是老兵他越是对自己的能力上限，他是有一个大概的评估的。


 就是在多么复杂度的情况下，他相信自己能做出非常好的判断，但是他也完全清楚在特定的复杂度下，他已经没办法做出他自己很自信的判断了。他这个时候他可能跟AI已经调试了很长时间，他觉得AI不会比自己差，说不定更好。因为反正他对自己在这个情况下，他是没有自信的，普通情况我觉得他们还是很有自信的，很正常。


 所以这个跟我们前面聊的又好像有点相反，就是说我前面说AI只适合做辅助性的工作，但是它的前提是当人觉得他能控制全局的时候，它适合做辅助性的，如果这个人自己都觉得自己没有把握控制全局的时候，他觉得我与其相信另外一个跟我一样，甚至比我差的人类不如赌一把AI。

庄老师 01:48:40
 我觉得不是这么看，我觉得是最终还是人判断。但是人的判断他选择了a或者是b这个其实是人的判断，只不过这个人的判断的 B的选项是AI做出的。

主持人李骏老师 01:49:03
 不是，我刚才的意思是说，其实人已经判断不了 AI的东西。

庄老师 01:49:07
 但是, 就是这么说，这件事情最终不能自动化，不能说必须要领悟到最后一步，这个人他可以去选择相信AI的判断，但是不能说我都不管了，你自己开火。

主持人李骏老师 01:49:23
 对这个倒是这倒是。这就像流浪地球里面说的，AI的所有决策必须要交人类去review才能够做，就不能完全delegate，不能完全委托给他不管了。

庄老师 01:49:38
 而且就是说你看一个有经验的飞行员，他可以做出这样的委托，我们也相信因为他是有经验的飞行员，所以他的委托我们可以信任。

主持人李骏老师 01:49:49
 对，在那个时候可能委托就最好的选择了，有道理。

王老师 01:49:55
 还有一个。

主持人李骏老师 01:49:56
 很哲学了。

王老师 01:49:57
 对很哲学了，对。


 还有一个因素就是这个人专家对AI的熟悉和信任程度，特别是他和他有过一定时间好的这种交互，比如说我们一起来做决策，虽然每次都是我做的决策，但是你每次给的我的一些建议，我觉得都还挺好的，其实就有点像开源社区里面的一些代码能用，虽然是陌生人，但是我跟你交互一段时间，我发现你是一个值得信任的，当我在一个复杂的问题上面，我可能自己也不是那么清楚，但是你给出来一个方案，我可能是比较倾向于接受你的方案。


 对，我觉得这个也是一点。


 是的。

庄老师 01:50:40
 当然我再多说一句，最终人类被机器人毁灭也是因为这个原因。

王老师 01:50:47
 Haha有可能我。


 是那个意思对吧？

庄老师 01:50:51
 你就信任对吧？他1000次都没犯过错对吧？最后不就完了吗？

王老师 01:50:56
 关键那一次。
 对。

主持人李骏老师 01:50:58
 所以为什么我之前说 Life3.0，然后像马斯克他们讲的那些东西，我哪怕是时间点选择它的话，我还得留一手，比如说之后要定期检查结果，然后如果这个事情是赌上命运的话，我至少还得把最后 Kill Switch, 能够最后杀死电脑的电源开关还要掌握在自己手里，还是要有一些所谓的 safeguard的一些安全上的限制才行。


 Ai应该怎么帮助人的一些思考，一些比较新的想法，今天正好可以系统性跟大家去聊一聊。Ok关于还有什么其他要补充吗？

庄老师 01:51:50
 没有了。好。

主持人李骏老师 01:51:53
 我们今天也聊了很长时间了，大概就到这里，谢谢大家。

王老师 01:51:57
 好，拜拜。